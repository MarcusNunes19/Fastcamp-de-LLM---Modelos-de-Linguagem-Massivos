{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-Groq"
      ],
      "metadata": {
        "id": "Juw-gSbmr4Kq"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "z9QiZT4Erl1s"
      },
      "outputs": [],
      "source": [
        "#Biblioteca do colab para obter a chave token\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os #vai ajudar a pegar o token\n",
        "from langchain.prompts import PromptTemplate #biblioteca do template que vou fazer\n",
        "from langchain_groq import ChatGroq #site que vou usar para pegar os modelos\n",
        "from langchain.chains import LLMChain # função para conectar os componentes(Chains)"
      ],
      "metadata": {
        "id": "dV872DdFr0lZ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pegando meu token e escolhendo o modelo que vou utilizar\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get(\"Croq\")\n",
        "meu_modelo = ChatGroq(model=\"llama3-8b-8192\", temperature = 0)"
      ],
      "metadata": {
        "id": "2j680s_zsXmf"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Criando um armazenamento para o meu chat**"
      ],
      "metadata": {
        "id": "qIztMNQYwPEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.chat_history import(\n",
        "    BaseChatMessageHistory,\n",
        "    InMemoryChatMessageHistory\n",
        ")\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "#O banco de mensagens é um dicionário que armazena o conteúdo das conversas\n",
        " # atrelados a um id(que representa uma sessão de conversa)\n",
        "\n",
        "banco_mensagens= {} # É aqui que o histórico de conversas vai ficar\n",
        "\n",
        "def pegar_historico_conversas(session_id: str) -> BaseChatMessageHistory:\n",
        "  if session_id not in banco_mensagens:\n",
        "    banco_mensagens[session_id] = InMemoryChatMessageHistory()\n",
        "  return banco_mensagens[session_id]\n",
        "\n",
        "#Juntando meu modelo com a função de armazenamento\n",
        "with_message_history= RunnableWithMessageHistory(meu_modelo, pegar_historico_conversas )\n"
      ],
      "metadata": {
        "id": "ioV63MVDs34V"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aqui testo a capacidade de memorização\n",
        "\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "with_message_history.invoke(\n",
        "    HumanMessage(content=\"Olá, meu nome é Marcus e eu adoro comer açaí\"),\n",
        "    config= {\"configurable\": {\"session_id\": \"1\"}} #Aqui passo o id da conversa. Sera armazenada com key \"1\" dentro do dicionário de memória\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpUMuSM8tS45",
        "outputId": "e368722b-ac3b-43a6-be8d-3634cf5e2fd3"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Olá Marcus! Prazer em conhecê-lo! Ah, você é um fã do açaí, é? É um fruto delicioso e muito saudável, não é? Qual é o seu modo preferido de consumir açaí? Você gosta de tomar smoothie, fazer açaí bowl, ou talvez usar açaí como ingrediente em receitas culinárias?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 25, 'total_tokens': 113, 'completion_time': 0.067588772, 'prompt_time': 0.006323869, 'queue_time': 0.11530298, 'total_time': 0.073912641}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--d398f3bc-43d4-4d35-adf8-5eaeabdebc16-0', usage_metadata={'input_tokens': 25, 'output_tokens': 88, 'total_tokens': 113})"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with_message_history.invoke(\n",
        "    HumanMessage(content=\"Olá, você lemnbra do meu nome e do que eu adoro?\"),\n",
        "    config = {\"configurable\": {\"session_id\": \"1\"}}\n",
        ")\n",
        "\n",
        "#Aqui vejo que ele se lembrou do que eu falei pra ele antes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuKmpNQe0pwz",
        "outputId": "9e3a02a8-6267-49f8-ce8b-969511729dbd"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Sim! Eu me lembro perfeitamente! Você se chama Marcus e você adora comer açaí!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 139, 'total_tokens': 165, 'completion_time': 0.020016451, 'prompt_time': 0.016882826, 'queue_time': 0.680710709, 'total_time': 0.036899277}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--29f97dc9-14d2-4928-8bd2-9e0820db8dba-0', usage_metadata={'input_tokens': 139, 'output_tokens': 26, 'total_tokens': 165})"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Aqui faço um simples propmt para meu chatbot, nada que eu não tenha visto antes\n",
        "#Após faze-lo eu acorrento(faço uma chain) com ele e meu modelo\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\",\n",
        "         \"Você é um assistente, responda o melhor que puder.\"\n",
        "         ),MessagesPlaceholder(variable_name=\"messages\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | meu_modelo"
      ],
      "metadata": {
        "id": "COYpCXRv3cDf"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = chain.invoke({\"messages\": [HumanMessage(content=\"Olá, sou Pablo\")]})\n",
        "\n",
        "resposta.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "MsQqvJBEcxsa",
        "outputId": "c5f4413d-02ae-4ec7-a34d-9a1a956278f0"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Olá Pablo! Prazer em conhecê-lo! Estou aqui para ajudá-lo com qualquer coisa que precise. Qual é o seu objetivo ou o que você gostaria de discutir?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with_message_history= RunnableWithMessageHistory(chain, pegar_historico_conversas)"
      ],
      "metadata": {
        "id": "etGNJm0odfYf"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta2= with_message_history.invoke(\n",
        "    HumanMessage(content= \"Olá, meu nome é Pablo. Gosto de açucar\"),\n",
        "    config= {\"configurable\": {\"session_id\": \"2\"}}\n",
        ")\n",
        "\n",
        "resposta2.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "UNUswpLXd1XV",
        "outputId": "2f77449b-dc0a-4b2f-d952-56b79fc99e91"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Olá Pablo! Prazer em conhecê-lo! Ah, você gosta de açúcar, é? Qual é o seu tipo de açúcar favorito? Você prefere o doce, o salgado ou algo mais exótico?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta2= with_message_history.invoke(\n",
        "    [HumanMessage(content=\"Olá, quem sou eu?\")],\n",
        "    config= {\"configurable\": {\"session_id\": \"2\"}}\n",
        ")\n",
        "\n",
        "resposta2.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "tpfYdFAneSRu",
        "outputId": "a933fc2a-833b-48f0-f997-03e62db98373"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Olá Pablo! Você é você mesmo! Eu sou o seu assistente, aqui para ajudá-lo com qualquer coisa que precise.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testando prompt novamente, mas dessa vez com variáveis. Aqui coloquei linguagem\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "  [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
        "    ),\n",
        "    MessagesPlaceholder(variable_name= \"messages\"),\n",
        "  ]\n",
        ")\n",
        "\n",
        "chain = prompt | meu_modelo"
      ],
      "metadata": {
        "id": "DCDDxhQ4e9H_"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setei como Coreano\n",
        "\n",
        "resposta2 = chain.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Olá, sou Arthur!\")], \"language\":\"Coreano\"}\n",
        ")\n",
        "\n",
        "resposta2.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_bigdj4rgwMw",
        "outputId": "f23e8837-604b-4bfe-e5d1-8a8ad30db1c6"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Annyeonghaseyo! (안녕하세요!) Nice to meet you, Arthur!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with_message_history = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    pegar_historico_conversas,\n",
        "    input_messages_key=\"messages\"\n",
        ")"
      ],
      "metadata": {
        "id": "aqWTe3y2hpKI"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta3= with_message_history.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Hello, how are you feeling today?\")], \"language\":\"Coreano\"},\n",
        "    config= {\"configurable\": {\"session_id\": \"3\"}}\n",
        ")\n",
        "\n",
        "resposta3.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "KbSPtf37i7dE",
        "outputId": "ff0e7cfb-9fcf-421f-c8d5-0c43567e69e8"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"! (annyeonghaseyo! jeoneun joheunhamnida) - Hello! I'm doing well, thank you for asking. How about you?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Managing Conversation History**"
      ],
      "metadata": {
        "id": "rYXTCj0Jm9vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Aqui posso definir meu próprio histórico e setar alguns parâmetros\n",
        "\n",
        "from langchain_core.messages import SystemMessage, trim_messages\n",
        "from langchain_core.messages import AIMessage\n",
        "\n",
        "#Aqui defino alguns parâmetros\n",
        "trimmer = trim_messages(\n",
        "    max_tokens=65,\n",
        "    strategy= \"last\",\n",
        "    token_counter= meu_modelo,\n",
        "    include_system= True,\n",
        "    allow_partial= False,\n",
        "    start_on= \"human\",\n",
        ")\n",
        "\n",
        "#A partir desse histórico consigo dar mais conhecimento para meu bot.\n",
        "messages = [\n",
        "    SystemMessage(content=\"Você é um assistente\"),\n",
        "    HumanMessage(content=\"Olá, sou Marcus\"),\n",
        "    AIMessage(content=\"olá!\"),\n",
        "    HumanMessage(content=\"Eu gosto de sorvete de açaí\"),\n",
        "    AIMessage(content=\"bacana\"),\n",
        "    HumanMessage(content=\"quanto é 2 + 2?\"),\n",
        "    AIMessage(content=\"4\"),\n",
        "    HumanMessage(content=\"obrigado\"),\n",
        "    AIMessage(content=\"sem problemas\"),\n",
        "]\n",
        "\n",
        "trimmer.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlvPH267j3FI",
        "outputId": "5283e0b4-836a-4dc8-8e65-18964741a003"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='Você é um assistente', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='Olá, sou Marcus', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='olá!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='Eu gosto de sorvete de açaí', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='bacana', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='quanto é 2 + 2?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='obrigado', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='sem problemas', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "\n",
        "#Acorrentando o prompt, modelo e o trimmer que eu criei\n",
        "chain = (\n",
        "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") |trimmer)\n",
        "    | prompt\n",
        "    | meu_modelo\n",
        ")\n",
        "\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"Qual é meu nome?\")],\n",
        "        \"language\": \"spanish\",\n",
        "\n",
        "    }\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "RiTDj_cnnpaK",
        "outputId": "369b2ae6-1953-4b04-bdb8-6a94a3c62fdf"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Lo siento, pero como soy un asistente artificial, no tengo información sobre tu nombre. ¿Quieres decirme quién eres?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
        "        \"language\": \"English\",\n",
        "    }\n",
        ")\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AC264U2VrIlx",
        "outputId": "c0773170-f49d-468f-c0ff-899ecb51f86d"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You asked: \"quanto é 2 + 2?\" which is Portuguese for \"what is 2 + 2?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OA7mtlwjrzKF"
      },
      "execution_count": 84,
      "outputs": []
    }
  ]
}
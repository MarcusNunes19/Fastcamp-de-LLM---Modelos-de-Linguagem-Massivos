{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDeWfDBdPXvB",
        "outputId": "bdec22ba-8ba8-483c-c646-554d56e7685f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt-core-news-lg==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-3.7.0/pt_core_news_lg-3.7.0-py3-none-any.whl (568.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.2/568.2 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from pt-core-news-lg==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.1.2)\n",
            "Installing collected packages: pt-core-news-lg\n",
            "Successfully installed pt-core-news-lg-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "#Before using and applying the model, it's necessary to download the large portuguese model\n",
        " #which has more features than the other two\n",
        "\n",
        "!python -m spacy download 'pt_core_news_lg'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Impoting the Spacy library and loading the trained model then instantiating a class\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('pt_core_news_lg')\n",
        "print(type(nlp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dclLOv6QNiF",
        "outputId": "a91e4dba-cf71-4623-dc0e-2495d3b3efbd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'spacy.lang.pt.Portuguese'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(nlp.pipe_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOUfbT1ASLeX",
        "outputId": "0ef3422e-8bf4-4507-e25f-2dd9052bef5a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tok2vec', 'morphologizer', 'parser', 'lemmatizer', 'attribute_ruler', 'ner']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This function processes these two texts through the pipeline that was shown in the code above\n",
        "\n",
        "text = nlp(\"Eu adoraria tomar uma xícara de chá de baixo da catedral de Paris, esse texto não foi gerado por IA\")\n",
        "text2 = nlp(\"As ávores são seres vivos muito importantes para o controle do aquecimento global\")"
      ],
      "metadata": {
        "id": "pBrEZ0_sQQsB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#As it can be seen, the words were made into tokens\n",
        "\n",
        "for token in text:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAks_CjhRvgK",
        "outputId": "0bffc770-6782-4885-d545-965a03aa19f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eu\n",
            "adoraria\n",
            "tomar\n",
            "uma\n",
            "xícara\n",
            "de\n",
            "chá\n",
            "de\n",
            "baixo\n",
            "da\n",
            "catedral\n",
            "de\n",
            "Paris\n",
            ",\n",
            "esse\n",
            "texto\n",
            "não\n",
            "foi\n",
            "gerado\n",
            "por\n",
            "IA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#There is a possibility to check propeties related to the tokens\n",
        "\n",
        "print(\"Tokens:\", [token.text for token in text2]) #prints all tokens\n",
        "print(\"Stop word:\", [token.text for token in text2 if token.is_stop]) #Check if a token is a stop word\n",
        "print(\"Maiúsculo:\", [token.is_upper for token in text2]) #check if has upper scale word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6g7CaDzS2VS",
        "outputId": "5f72cdc5-1e19-43b3-9720-e416580697a2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['As', 'ávores', 'são', 'seres', 'vivos', 'muito', 'importantes', 'para', 'o', 'controle', 'do', 'aquecimento', 'global']\n",
            "Stop word: ['As', 'são', 'muito', 'para', 'o', 'do']\n",
            "Maiúsculo: [False, False, False, False, False, False, False, False, False, False, False, False, False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It's also possible to check Pos-Taggin, feature which classify tokens as it can be seen bellow\n",
        "\n",
        "text3 = nlp(\"O Imperador viveu por 200 anos no Brasil e depois se mudou para a Coreia do Sul para tomar café\")\n",
        "\n",
        "for token in text3:\n",
        "  print(token.text, \" - \", token.pos_, \" - \", token.shape_, \" - \", token.dep_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdT2UXdfUdvY",
        "outputId": "d041a2ec-6b46-4c83-e6fb-a4d8ec1c4811"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O  -  DET  -  X  -  det\n",
            "Imperador  -  PROPN  -  Xxxxx  -  nsubj\n",
            "viveu  -  VERB  -  xxxx  -  ROOT\n",
            "por  -  ADP  -  xxx  -  case\n",
            "200  -  NUM  -  ddd  -  nummod\n",
            "anos  -  NOUN  -  xxxx  -  obl\n",
            "no  -  ADP  -  xx  -  case\n",
            "Brasil  -  PROPN  -  Xxxxx  -  obl\n",
            "e  -  CCONJ  -  x  -  cc\n",
            "depois  -  ADV  -  xxxx  -  advmod\n",
            "se  -  PRON  -  xx  -  expl\n",
            "mudou  -  VERB  -  xxxx  -  conj\n",
            "para  -  ADP  -  xxxx  -  case\n",
            "a  -  DET  -  x  -  det\n",
            "Coreia  -  PROPN  -  Xxxxx  -  obl\n",
            "do  -  ADP  -  xx  -  case\n",
            "Sul  -  PROPN  -  Xxx  -  nmod\n",
            "para  -  SCONJ  -  xxxx  -  mark\n",
            "tomar  -  VERB  -  xxxx  -  advcl\n",
            "café  -  NOUN  -  xxxx  -  obj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text3 = nlp(\"A Imperadora,junto com sua prima, viveu por 200 anos no Brasil e depois se mudou para a Coreia do Sul para tomar café\")\n",
        "\n",
        "for token in text3:\n",
        "  print(token.text, \" - \", token.morph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJmWA6btWUH2",
        "outputId": "9df6540a-78fe-4a3a-fbe4-95e8221eaad0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A  -  Definite=Def|Gender=Fem|Number=Sing|PronType=Art\n",
            "Imperadora  -  Gender=Fem|Number=Sing\n",
            ",  -  \n",
            "junto  -  \n",
            "com  -  \n",
            "sua  -  Gender=Fem|Number=Sing|PronType=Prs\n",
            "prima  -  Gender=Fem|Number=Sing\n",
            ",  -  \n",
            "viveu  -  Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\n",
            "por  -  \n",
            "200  -  NumType=Card\n",
            "anos  -  Gender=Masc|Number=Plur\n",
            "no  -  Definite=Def|Gender=Masc|Number=Sing|PronType=Art\n",
            "Brasil  -  Gender=Masc|Number=Sing\n",
            "e  -  \n",
            "depois  -  \n",
            "se  -  Case=Acc|Gender=Masc|Number=Sing|Person=3|PronType=Prs\n",
            "mudou  -  Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\n",
            "para  -  \n",
            "a  -  Definite=Def|Gender=Fem|Number=Sing|PronType=Art\n",
            "Coreia  -  Gender=Fem|Number=Sing\n",
            "do  -  Definite=Def|Gender=Masc|Number=Sing|PronType=Art\n",
            "Sul  -  Number=Sing\n",
            "para  -  \n",
            "tomar  -  VerbForm=Inf\n",
            "café  -  Gender=Masc|Number=Sing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#It's possible to check the level o similarity between two texts\n",
        "\n",
        "text4 = nlp(\"Mario gosta muito da culinária da Coreia, pois adora comida apimentada\")\n",
        "text5 = nlp(\"Maria adora pouco da culinária Coreana, pois não gosta tanto de comida apimentada\")\n",
        "\n",
        "print(text4.similarity(text5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z7U68kRY1Mu",
        "outputId": "12d49eb5-7c88-4186-ebe7-9c3c3f0133bb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8818369857779318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "displacy.render(text3, style=\"ent\",jupyter= True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "z3wGXnoDZnJK",
        "outputId": "0343dc03-9fcd-4bb8-db78-ea8653eda56d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Imperadora\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ",junto com sua prima, viveu por 200 anos no \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brasil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " e depois se mudou para a \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Coreia do Sul\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " para tomar café</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#It's also possible to find matches throuh patterns in texts\n",
        "\n",
        "from typing import Match\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "text4 = nlp(\"America é um país. EUA é um país. Estados Unidos é um pais\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "padrão1 = [{\"LOWER\": \"America\"}]\n",
        "padrão2 = [{\"LOWER\": \"EUA\"}]\n",
        "padrão3 = [{\"LOWER\": \"Estados\"}, {\"LOWER\": \"Unidos\"}]\n",
        "\n",
        "matcher.add(\"padrão\", [padrão1, padrão2, padrão3])\n",
        "\n",
        "matches = matcher(text4)\n",
        "for id, inicio, fim in matches:\n",
        "  print(text4[inicio:fim])"
      ],
      "metadata": {
        "id": "6NTcGhWoaZhV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wZ8iX-YnAui8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}